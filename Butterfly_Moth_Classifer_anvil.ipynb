{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737f8aca-c15b-4c9b-a9f3-b7af62348ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 15:37:18.386746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-11 15:37:18.386772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16490254-09ca-4af1-8edc-59554229f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n",
    "             interpolation='nearest'):\n",
    "    \"\"\"Loads an image into PIL format.\n",
    "    # Arguments\n",
    "        path: Path to image file.\n",
    "        color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "            The desired image format.\n",
    "        target_size: Either `None` (default to original size)\n",
    "            or tuple of ints `(img_height, img_width)`.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "            target size is different from that of the loaded image.\n",
    "            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
    "            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "            \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "        ValueError: if interpolation method is not supported.\n",
    "    \"\"\"\n",
    "    if grayscale is True:\n",
    "        warnings.warn('grayscale is deprecated. Please use '\n",
    "                      'color_mode = \"grayscale\"')\n",
    "        color_mode = 'grayscale'\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `array_to_img` requires PIL.')\n",
    "    img = pil_image.open(path)\n",
    "    if color_mode == 'grayscale':\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "    elif color_mode == 'rgba':\n",
    "        if img.mode != 'RGBA':\n",
    "            img = img.convert('RGBA')\n",
    "    elif color_mode == 'rgb':\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "    else:\n",
    "        raise ValueError('color_mode must be \"grayscale\", \"rgb\", or \"rgba\"')\n",
    "    if target_size is not None:\n",
    "        width_height_tuple = (target_size[1], target_size[0])\n",
    "        if img.size != width_height_tuple:\n",
    "            if interpolation not in _PIL_INTERPOLATION_METHODS:\n",
    "                raise ValueError(\n",
    "                    'Invalid interpolation method {} specified. Supported '\n",
    "                    'methods are {}'.format(\n",
    "                        interpolation,\n",
    "                        \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n",
    "            resample = _PIL_INTERPOLATION_METHODS[interpolation]\n",
    "            img = img.resize(width_height_tuple, resample)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a14c69-9de4-47af-ae92-c16d62669a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(img, data_format='channels_last', dtype='float32'):\n",
    "    \"\"\"Converts a PIL Image instance to a Numpy array.\n",
    "    # Arguments\n",
    "        img: PIL Image instance.\n",
    "        data_format: Image data format,\n",
    "            either \"channels_first\" or \"channels_last\".\n",
    "        dtype: Dtype to use for the returned array.\n",
    "    # Returns\n",
    "        A 3D Numpy array.\n",
    "    # Raises\n",
    "        ValueError: if invalid `img` or `data_format` is passed.\n",
    "    \"\"\"\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format: %s' % data_format)\n",
    "    # Numpy array x has format (height, width, channel)\n",
    "    # or (channel, height, width)\n",
    "    # but original PIL image has format (width, height, channel)\n",
    "    x = np.asarray(img, dtype=dtype)\n",
    "    if len(x.shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.transpose(2, 0, 1)\n",
    "    elif len(x.shape) == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        else:\n",
    "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "    else:\n",
    "        raise ValueError('Unsupported image shape: %s' % (x.shape,))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fab3ed-26a2-45c2-84f3-a820e0d0b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path = \"training_1/cp.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b836ab3-e9c8-4657-9706-6d9ec4d6d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 15:37:19.992126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-11 15:37:19.992157: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-11 15:37:19.992188: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lion-tva2): /proc/driver/nvidia/version does not exist\n",
      "2022-02-11 15:37:19.992434: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambd (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLamb (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,862,721\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "model = tf.keras.models.load_model('../saved_model/my_butterfly_model')\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201193ec-6e2b-483b-a5d8-c2cfc4dcd3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"OPQ6OKND6NDUAENE3HW7N452-A26TAOHW2XOOPAQV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf3013e-e8f5-4721-bbea-2d8427b2a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "\n",
    "@anvil.server.callable\n",
    "def classify_image(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        img = load_img(filename)\n",
    "    # Inside the classify_image function\n",
    "\n",
    "    img = img.resize((160, 160), resample=pil_image.BICUBIC)\n",
    "    arr = img_to_array(img)\n",
    "    #print(arr)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr /= 255\n",
    "    # Inside the classify_image function\n",
    "\n",
    "    score = model.predict(arr)\n",
    "    \n",
    "    #predictions = tf.nn.sigmoid(score)\n",
    "    predictions = tf.where(score < 0.5, 0, 1)\n",
    "    \n",
    "    return ('Butterflies' if score < 0.5 else 'Moths', float(score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610623b-c0ab-47b5-86ac-a12419d3b39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
